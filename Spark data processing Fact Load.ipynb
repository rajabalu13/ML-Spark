{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"C:/Users/Dinesh_2/Desktop/1000 Sales Records.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_src = spark.read.format(file_type) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .option(\"encoding\", \"UTF-8\") \\\n",
    "  .load(file_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Row ID: string (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Ship Date: string (nullable = true)\n",
      " |-- Ship Mode: string (nullable = true)\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Name: string (nullable = true)\n",
      " |-- Segment: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Postal Code: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Sub-Category: string (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Sales: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Discount: string (nullable = true)\n",
      " |-- Profit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_src.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Row ID: string (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Order Date: date (nullable = true)\n",
      " |-- Ship Date: string (nullable = true)\n",
      " |-- Ship Mode: string (nullable = true)\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Name: string (nullable = true)\n",
      " |-- Segment: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Postal Code: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Sub-Category: string (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Sales: decimal(23,4) (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Discount: decimal(23,4) (nullable = true)\n",
      " |-- Profit: decimal(23,4) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_src=df_src.withColumn('Order Date',F.col('Order Date').cast('Date')).withColumn('Quantity',F.col('Quantity').cast('int')).withColumn('Sales',F.col('Sales').cast('decimal(23,4)')).withColumn('Discount',F.col('Discount').cast('decimal(23,4)')).withColumn('Profit',F.col('Profit').cast('decimal(23,4)'))\n",
    "df_src.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+---------------+--------------------+---------+--------+-------------------+\n",
      "|     Customer Name|      Country|           City|        Product Name|    Sales|Quantity|              Price|\n",
      "+------------------+-------------+---------------+--------------------+---------+--------+-------------------+\n",
      "|       Claire Gute|United States|      Henderson|Bush Somerset Col...| 261.9600|       2|130.980000000000000|\n",
      "|       Claire Gute|United States|      Henderson|Hon Deluxe Fabric...| 731.9400|       3|243.980000000000000|\n",
      "|   Darrin Van Huff|United States|    Los Angeles|Self-Adhesive Add...|  14.6200|       2|  7.310000000000000|\n",
      "|    Sean O'Donnell|United States|Fort Lauderdale|Bretford CR4500 S...| 957.5775|       5|191.515500000000000|\n",
      "|    Sean O'Donnell|United States|Fort Lauderdale|Eldon Fold 'N Rol...|  22.3680|       2| 11.184000000000000|\n",
      "|   Brosina Hoffman|United States|    Los Angeles|Eldon Expressions...|  48.8600|       7|  6.980000000000000|\n",
      "|   Brosina Hoffman|United States|    Los Angeles|          Newell 322|   7.2800|       4|  1.820000000000000|\n",
      "|   Brosina Hoffman|United States|    Los Angeles|Mitel 5320 IP Pho...| 907.1520|       6|151.192000000000000|\n",
      "|   Brosina Hoffman|United States|    Los Angeles|DXL Angle-View Bi...|  18.5040|       3|  6.168000000000000|\n",
      "|   Brosina Hoffman|United States|    Los Angeles|Belkin F5C206VTEL...| 114.9000|       5| 22.980000000000000|\n",
      "|   Brosina Hoffman|United States|    Los Angeles|Chromcraft Rectan...|1706.1840|       9|189.576000000000000|\n",
      "|   Brosina Hoffman|United States|    Los Angeles|Konftel 250 Confe...| 911.4240|       4|227.856000000000000|\n",
      "|      Andrew Allen|United States|        Concord|          Xerox 1967|  15.5520|       3|  5.184000000000000|\n",
      "|      Irene Maddox|United States|        Seattle|Fellowes PB200 Pl...| 407.9760|       3|135.992000000000000|\n",
      "|     Harold Pawlan|United States|     Fort Worth|Holmes Replacemen...|  68.8100|       5| 13.762000000000000|\n",
      "|     Harold Pawlan|United States|     Fort Worth|Storex DuraTech R...|   2.5440|       3|  0.848000000000000|\n",
      "|         Pete Kriz|United States|        Madison|\"Stur-D-Stor Shel...| 665.8800|       6|110.980000000000000|\n",
      "|   Alejandro Grove|United States|    West Jordan|Fellowes Super St...|  55.5000|       2| 27.750000000000000|\n",
      "|Zuschuss Donatelli|United States|  San Francisco|          Newell 341|   8.5600|       2|  4.280000000000000|\n",
      "|Zuschuss Donatelli|United States|  San Francisco|Cisco SPA 501G IP...| 213.4800|       3| 71.160000000000000|\n",
      "+------------------+-------------+---------------+--------------------+---------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_src=df_src.withColumn('Price',df_src.Sales/df_src.Quantity)\n",
    "df_src.select('Customer Name','Country','City','Product Name','Sales','Quantity','Price').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_src=df_src.withColumnRenamed('Order Date','Order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_src.createOrReplaceTempView('df_src')\n",
    "df_tgt=spark.sql(\"select * from df_src where Order_date<=(select date_add(max(Order_date),-90) from df_src)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(c=8787)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tgt.agg(F.count(df_tgt.Order_date).alias('c')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(c=9994)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_src.agg(F.count(df_src.Order_date).alias('c')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|MAX_ORDER_DATE|\n",
      "+--------------+\n",
      "|    2017-10-01|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tgt.createOrReplaceTempView('df_tgt_table')\n",
    "df_maxtgt_date = spark.sql(\"select max(Order_date)as MAX_ORDER_DATE from df_tgt_table\")\n",
    "\n",
    "df_maxtgt_date.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(c=1207)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maxtgt_date.createOrReplaceTempView('df_maxtgt_date')\n",
    "df_delta=spark.sql(\"select * from df_src where Order_date>(select MAX_ORDER_DATE from df_maxtgt_date)\")\n",
    "df_delta.agg(F.count(df_delta.Order_date).alias('c')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(c=9994)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final=df_tgt.union(df_delta)\n",
    "df_final.agg(F.count(df_final.Order_date).alias('c')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
